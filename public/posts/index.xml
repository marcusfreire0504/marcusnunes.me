<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Marcus Nunes&#39; Blog</title>
		<link>https://marcusnunes.me/posts/</link>
		<description>Recent content on Marcus Nunes&#39; Blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>pt-br</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Fri, 02 Feb 2018 12:00:00 -0300</lastBuildDate>
		<atom:link href="https://marcusnunes.me/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Algumas das piores visualizações de dados já feitas na história das eleições brasileiras e mundiais</title>
			<link>https://marcusnunes.me/posts/algumas-das-piores-visualizacoes-de-dados-ja-feitas/</link>
			<pubDate>Thu, 27 Feb 2020 07:57:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/algumas-das-piores-visualizacoes-de-dados-ja-feitas/</guid>
			<description>2020 é ano de eleição. O que não falta nesta época do ano são eleitores, veículos de imprensa e assessorias de candidatos tentam o possível (e, muitas vezes, o impossível) para mostrar que seus representantes são os melhores. Meu objetivo ao criar este post foi mostrar como é possível mascarar dados reais e mentir com visualizações erradas.
Presidência da Venezuela, 2013 Um belo exemplo de como exagerar na diferença do percentual de votos entre dois candidatos a presidente, levando o leitor a acreditar que ela é muito maior do que realmente é.</description>
			<content type="html"><![CDATA[

<p>2020 é ano de eleição. O que não falta nesta época do ano são eleitores, veículos de imprensa e assessorias de candidatos tentam o possível (e, muitas vezes, o impossível) para mostrar que seus representantes são os melhores. Meu objetivo ao criar este post foi mostrar como é possível mascarar dados reais e mentir com visualizações erradas.</p>

<h2 id="presidência-da-venezuela-2013">Presidência da Venezuela, 2013</h2>

<p><img src="/images/maduro.jpg" alt="Presidência da Venezuela, 2013" /></p>

<p>Um belo exemplo de como exagerar na diferença do percentual de votos entre dois candidatos a presidente, levando o leitor a acreditar que ela é muito maior do que realmente é.</p>

<h2 id="presidência-do-brasil-2018">Presidência do Brasil, 2018</h2>

<p><img src="/images/ipof.jpg" alt="Presidência do Brasil, 2018" /></p>

<p>Detalhe para quem se responsabiliza por esta pesquisa: Instituto de Pesquisa Oficial do Face. Sim, <em>Face</em>, não Facebook. Exemplo clássico de viés de seleção em pesquisa, pois provavelmente aqueles que votaram nela são apenas os que concordam com determinada</p>

<h2 id="prefeitura-do-rio-de-janeiro-2016">Prefeitura do Rio de Janeiro, 2016</h2>

<p><img src="/images/crivella_jandira.jpg" alt="Prefeitura do Rio de Janeiro, 2016" /></p>

<p>Além da diferença entre os dois candidatos não estar proporcional, veja como um ponto percentual faz a intenção de votos para Jandira Feghali subir mais intensamente do que os dois pontos percentuais de Marcelo Crivella fazem por sua intenção de voto.</p>

<h2 id="prefeitura-de-porto-alegre-2016">Prefeitura de Porto Alegre, 2016</h2>

<p>À primeira vista, somos levados a acreditar que Sebastião Melo é o líder da pesquisa eleitoral na cidade. Entretanto, ele estava em terceiro lugar no momento em que este gráfico foi divulgado.</p>

<p><img src="/images/melo.png" alt="Presidência do Brasil, 2018" /></p>

<h2 id="governo-de-são-paulo-2018">Governo de São Paulo, 2018</h2>

<p><img src="/images/doria_lidera.jpg" alt="Governo de São Paulo, 2018" /></p>

<p>Este é o meu gráfico preferido, pois não tem quase nada certo nele:</p>

<ul>
<li>os 22% do Doria estão próximos da escala de 90% do gráfico</li>
<li>graficamente, os 22% de Doria são mais de 4 vezes maiores do que os 15% de Skaf</li>
<li>além diss, estes mesmos 22% tem aproximadamente o dobro do tamanho dos 40% do percentual de indecisos</li>
<li>todos os outros candidatos estão desalinhados em relação às linhas de referência do gráfico</li>
<li>o símbolo de &ldquo;avança&rdquo;, feito pelo candidato na foto com a sua mão direita, aponta para a esquerda, que é a direção normalmente associada ao retrecesso</li>
</ul>

<h2 id="bônus-futebol">Bônus: Futebol</h2>

<p>Não conheço ninguém que tenha conseguido interpretar o gráfico abaixo em menos de 30 segundos. Tem gente inclusive que demora muito mais de um minuto para isso. Tente entender o que está representado abaixo e deixe a sua resposta nos comentários.</p>

<p><img src="/images/gols.jpg" alt="Bônus: Futebol" /></p>
]]></content>
		</item>
		
		<item>
			<title>Heatmap com os dados de geolocalização do Google Location History: minha viagem pela Itália</title>
			<link>https://marcusnunes.me/posts/heatmap-de-localizacao-no-google/</link>
			<pubDate>Mon, 27 Jan 2020 15:14:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/heatmap-de-localizacao-no-google/</guid>
			<description>Uma das coisas que mais gosto na modernidade são os serviços de localização. Sim, eu sei que a minha suposta privacidade é completamente perdida quando compartilho meus dados de localização o tempo todo, mas acredito que as facilidades que isso me traz superam, e muito, as desvantagens. O problema é que eu não sabia muito o que fazer com estes dados.
Mas eis que um usuário do github chamado luka1199 criou o repositório Generate an interactive geo heatmap from your Google location data para auxiliar na geração de heatmaps a partir dos dados de localização dos usuários.</description>
			<content type="html"><![CDATA[<p>Uma das coisas que mais gosto na modernidade são os serviços de localização. Sim, eu sei que a minha suposta privacidade é completamente perdida quando compartilho meus dados de localização o tempo todo, mas acredito que as facilidades que isso me traz superam, e muito, as desvantagens. O problema é que eu não sabia muito o que fazer com estes dados.</p>

<p>Mas eis que um usuário do github chamado <a href="https://github.com/luka1199/" target="_blank">luka1199</a> criou o repositório <a href="https://github.com/luka1199/geo-heatmap" target="_blank">Generate an interactive geo heatmap from your Google location data</a> para auxiliar na geração de heatmaps a partir dos dados de localização dos usuários. Ele permite que qualquer pessoa baixe seus dados do Google e gere, com muito pouco trabalho, visualizações interessantes sobre seus hábitos de movimentação.</p>

<p>Por exemplo, este é o heatmap que gerei a partir das minhas férias na Itália e Portugal, entre Dezembro de 2019 e Janeiro de 2020. Comecei em Veneza e de lá desci para Florença, Roma, Nápoles, Catânia, Siracusa, Agrigento e Palermo, para depois seguir para Lisboa e Sintra, em Portugal.</p>

<p><img src="/images/italia.png" alt="Mapa da Itália" /></p>

<p><img src="/images/portugal.png" alt="Mapa de Portugal" /></p>

<p>Logicamente, estas são imagens estáticas, mas ao final do post eu coloquei o mapa interativo para vocês verem como ele funciona na prática.</p>

<p>Para quem já tem um pouco de experiência com <a href="https://marcusnunes.me/tags/python" target="_blank">python</a>, o script é muito fácil de usar:</p>

<ol>
<li>Instale o <a href="https://www.python.org/downloads/" target="_blank">python 3+</a> em seu computador</li>
<li>Baixe seus dados de localização a partir do <a href="https://takeout.google.com/" target="_blank">Google Takeout</a></li>
<li>Clone o <a href="https://github.com/luka1199/geo-heatmap" target="_blank">repositório</a> com os scripts necessários em sua máquina local ou na nuvem</li>
<li>Rode o comando <code>pip install -r requirements.txt</code> na pasta com o repositório clonado</li>
<li>Por fim, execute <code>python geo_heatmap.py NomeDoArquivo.json</code> para gerar o seu mapa interativo</li>
</ol>

<p>O meu heatmap interativo pode ser visualizado abaixo:</p>

<iframe src="/images/heatmap.html" width=100% height=600></iframe>

<p>Comente aqui embaixo o que você achou dessa ferramenta. Ou, caso não tenha conseguido usá-la, relate as suas dificuldades.</p>

<p>Aproveite que chegou até aqui e me siga no <a href="https://instagram.com/grandeabobora/" target="_blank">instagram</a> para ver as fotos que estou publicando a respeito dessa viagem.</p>



<blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/B625CmDBMHU/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="12" style=" background:#FFF; border:0; border-radius:3px; box-shadow:0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width:658px; min-width:326px; padding:0; width:99.375%; width:-webkit-calc(100% - 2px); width:calc(100% - 2px);"><div style="padding:16px;"> <a href="https://www.instagram.com/p/B625CmDBMHU/?utm_source=ig_embed&amp;utm_campaign=loading" style=" background:#FFFFFF; line-height:0; padding:0 0; text-align:center; text-decoration:none; width:100%;" target="_blank"> <div style=" display: flex; flex-direction: row; align-items: center;"> <div style="background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;"></div> <div style="display: flex; flex-direction: column; flex-grow: 1; justify-content: center;"> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;"></div> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;"></div></div></div><div style="padding: 19% 0;"></div> <div style="display:block; height:50px; margin:0 auto 12px; width:50px;"><svg width="50px" height="50px" viewBox="0 0 60 60" version="1.1" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g transform="translate(-511.000000, -20.000000)" fill="#000000"><g><path d="M556.869,30.41 C554.814,30.41 553.148,32.076 553.148,34.131 C553.148,36.186 554.814,37.852 556.869,37.852 C558.924,37.852 560.59,36.186 560.59,34.131 C560.59,32.076 558.924,30.41 556.869,30.41 M541,60.657 C535.114,60.657 530.342,55.887 530.342,50 C530.342,44.114 535.114,39.342 541,39.342 C546.887,39.342 551.658,44.114 551.658,50 C551.658,55.887 546.887,60.657 541,60.657 M541,33.886 C532.1,33.886 524.886,41.1 524.886,50 C524.886,58.899 532.1,66.113 541,66.113 C549.9,66.113 557.115,58.899 557.115,50 C557.115,41.1 549.9,33.886 541,33.886 M565.378,62.101 C565.244,65.022 564.756,66.606 564.346,67.663 C563.803,69.06 563.154,70.057 562.106,71.106 C561.058,72.155 560.06,72.803 558.662,73.347 C557.607,73.757 556.021,74.244 553.102,74.378 C549.944,74.521 548.997,74.552 541,74.552 C533.003,74.552 532.056,74.521 528.898,74.378 C525.979,74.244 524.393,73.757 523.338,73.347 C521.94,72.803 520.942,72.155 519.894,71.106 C518.846,70.057 518.197,69.06 517.654,67.663 C517.244,66.606 516.755,65.022 516.623,62.101 C516.479,58.943 516.448,57.996 516.448,50 C516.448,42.003 516.479,41.056 516.623,37.899 C516.755,34.978 517.244,33.391 517.654,32.338 C518.197,30.938 518.846,29.942 519.894,28.894 C520.942,27.846 521.94,27.196 523.338,26.654 C524.393,26.244 525.979,25.756 528.898,25.623 C532.057,25.479 533.004,25.448 541,25.448 C548.997,25.448 549.943,25.479 553.102,25.623 C556.021,25.756 557.607,26.244 558.662,26.654 C560.06,27.196 561.058,27.846 562.106,28.894 C563.154,29.942 563.803,30.938 564.346,32.338 C564.756,33.391 565.244,34.978 565.378,37.899 C565.522,41.056 565.552,42.003 565.552,50 C565.552,57.996 565.522,58.943 565.378,62.101 M570.82,37.631 C570.674,34.438 570.167,32.258 569.425,30.349 C568.659,28.377 567.633,26.702 565.965,25.035 C564.297,23.368 562.623,22.342 560.652,21.575 C558.743,20.834 556.562,20.326 553.369,20.18 C550.169,20.033 549.148,20 541,20 C532.853,20 531.831,20.033 528.631,20.18 C525.438,20.326 523.257,20.834 521.349,21.575 C519.376,22.342 517.703,23.368 516.035,25.035 C514.368,26.702 513.342,28.377 512.574,30.349 C511.834,32.258 511.326,34.438 511.181,37.631 C511.035,40.831 511,41.851 511,50 C511,58.147 511.035,59.17 511.181,62.369 C511.326,65.562 511.834,67.743 512.574,69.651 C513.342,71.625 514.368,73.296 516.035,74.965 C517.703,76.634 519.376,77.658 521.349,78.425 C523.257,79.167 525.438,79.673 528.631,79.82 C531.831,79.965 532.853,80.001 541,80.001 C549.148,80.001 550.169,79.965 553.369,79.82 C556.562,79.673 558.743,79.167 560.652,78.425 C562.623,77.658 564.297,76.634 565.965,74.965 C567.633,73.296 568.659,71.625 569.425,69.651 C570.167,67.743 570.674,65.562 570.82,62.369 C570.966,59.17 571,58.147 571,50 C571,41.851 570.966,40.831 570.82,37.631"></path></g></g></g></svg></div><div style="padding-top: 8px;"> <div style=" color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;"> View this post on Instagram</div></div><div style="padding: 12.5% 0;"></div> <div style="display: flex; flex-direction: row; margin-bottom: 14px; align-items: center;"><div> <div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(0px) translateY(7px);"></div> <div style="background-color: #F4F4F4; height: 12.5px; transform: rotate(-45deg) translateX(3px) translateY(1px); width: 12.5px; flex-grow: 0; margin-right: 14px; margin-left: 2px;"></div> <div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(9px) translateY(-18px);"></div></div><div style="margin-left: 8px;"> <div style=" background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;"></div> <div style=" width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)"></div></div><div style="margin-left: auto;"> <div style=" width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);"></div> <div style=" background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);"></div> <div style=" width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);"></div></div></div></a> <p style=" margin:8px 0 0 0; padding:0 4px;"> <a href="https://www.instagram.com/p/B625CmDBMHU/?utm_source=ig_embed&amp;utm_campaign=loading" style=" color:#000; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px; text-decoration:none; word-wrap:break-word;" target="_blank">Que rua molhada essa aí #venice #veneza #italia #ferias #canoneosrp #canon24105rf #paisagem #city #streetphotography #street #afternoon</a></p> <p style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; line-height:17px; margin-bottom:0; margin-top:8px; overflow:hidden; padding:8px 0 7px; text-align:center; text-overflow:ellipsis; white-space:nowrap;">A post shared by <a href="https://www.instagram.com/grandeabobora/?utm_source=ig_embed&amp;utm_campaign=loading" style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px;" target="_blank"> Marcus Nunes</a> (@grandeabobora) on <time style=" font-family:Arial,sans-serif; font-size:14px; line-height:17px;" datetime="2020-01-03T12:34:31+00:00">Jan 3, 2020 at 4:34am PST</time></p></div></blockquote>
<script async src="//www.instagram.com/embed.js"></script>
]]></content>
		</item>
		
		<item>
			<title>Analise os dados abertos da ANAC</title>
			<link>https://marcusnunes.me/posts/dados-coletados-da-anac/</link>
			<pubDate>Thu, 26 Dec 2019 07:36:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/dados-coletados-da-anac/</guid>
			<description>Organizei todos os registros de voos do site da ANAC em um pacote do R. São mais de 20 milhões de informações referentes a todos os voos civis registrados no Brasil desde 2000, com as seguintes variáveis:
 ICAOEmpresaAerea - Código designador da empresa no padrão da ICAO, com três letras. NumeroVoo - Numeração do voo, com até 4 caracteres numéricos. CodigoAutorizacaoDI - Caractere utilizado para identificar o tipo de autorização para cada etapa de voo conforme IAC 1504, podendo ser 0 (voo regular), 1 (voo extra com HOTRAN), 2 (voo extra sem HOTRAN), 3 (voo de retorno), 4 (inclusão de etapa em um voo previsto em HOTRAN), 5 (voo cargueiro), 6 (voo de serviço), 7 (voo de fretamento), 9 (voo charter), A (voo de instrução) ou B (voo de experiência).</description>
			<content type="html"><![CDATA[<p>Organizei todos os registros de voos do site da ANAC em um pacote do R. São mais de 20 milhões de informações referentes a todos os voos civis registrados no Brasil desde 2000, com as seguintes variáveis:</p>

<ul>
<li><code>ICAOEmpresaAerea</code> - Código designador da empresa no padrão da ICAO, com três letras.</li>
<li><code>NumeroVoo</code> - Numeração do voo, com até 4 caracteres numéricos.</li>
<li><code>CodigoAutorizacaoDI</code> - Caractere utilizado para identificar o tipo de autorização para cada etapa de voo conforme IAC 1504, podendo ser 0 (voo regular), 1 (voo extra com HOTRAN), 2 (voo extra sem HOTRAN), 3 (voo de retorno), 4 (inclusão de etapa em um voo previsto em HOTRAN), 5 (voo cargueiro), 6 (voo de serviço), 7 (voo de fretamento), 9 (voo charter), A (voo de instrução) ou B (voo de experiência).</li>
<li><code>CodigoTipoLinha</code> - Identifica o tipo de operação realizada, conforme IAC 1504, sendo N (nacional), I (internacional), R (regional), H (sub-regional), E (especial), C (cargueiro), G (cargueiro internacional) e L (rede postal).</li>
<li><code>ICAOAerodromoOrigem</code> - Código ICAO do aeroporto de origem.</li>
<li><code>ICAOAerodromoDestino</code> - Código ICAO do aeroporto de destino.</li>
<li><code>PartidaPrevista</code> - Data e horário da partida prevista em horário de Brasília.</li>
<li><code>PartidaReal</code> - Data e horário da partida realizada informada pela empresa aérea, em horário de Brasília.</li>
<li><code>ChegadaPrevista</code> - Data e horário da chegada prevista em horário de Brasília.</li>
<li><code>ChegadaReal</code> - Data e horário da chegada realizada, informada pela empresa aérea, em horário de Brasília.</li>
<li><code>SituacaoVoo</code> - Campo informando se o voo foi realizado ou cancelado.</li>
<li><code>CodigoJustificativa</code> - Identifica o motivo do atraso, cancelamento e demais alterações em relação ao voo planejado, conforme IAC 1504.</li>
</ul>

<p><a href="https://github.com/mnunes/anac/" target="_blank">Visite meu github</a> para encontrar o link para baixar o pacote e as suas instruções de uso.</p>
]]></content>
		</item>
		
		<item>
			<title>Como simplificar seus relatórios estatísticos usando R Markdown</title>
			<link>https://marcusnunes.me/posts/como-simplificar-seus-relato%CC%81rios-estati%CC%81sticos-usando-r-markdown/</link>
			<pubDate>Mon, 18 Nov 2019 21:55:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/como-simplificar-seus-relato%CC%81rios-estati%CC%81sticos-usando-r-markdown/</guid>
			<description>Hoje apresentei mais um minicurso. A organização da 2nd Conference on Statistics and Data Science me chamou para contribuir com um assunto referente à ciência de dados no evento. Escolhi falar sobre R Markdown, a tecnologia que utilizamos para escrever os relatórios de consultoria do Laboratório de Estatística Aplicada. Inclusive, temos um pacote no R chamado modeloLEA, escrito para agilizar e padronizar a formatação destes nossos relatórios.
O material do minicurso pode ser acessado em github.</description>
			<content type="html"><![CDATA[<p>Hoje apresentei mais um minicurso. A organização da <a href="http://www.csds2019.ime.ufba.br/" target="_blank">2nd Conference on Statistics and Data Science</a> me chamou para contribuir com um assunto referente à ciência de dados no evento. Escolhi falar sobre <a href="https://marcusnunes.me/tags/r%20markdown/" target="_blank">R Markdown</a>, a tecnologia que utilizamos para escrever os relatórios de consultoria do <a href="http://lea.estatistica.ccet.ufrn.br/" target="_blank">Laboratório de Estatística Aplicada</a>. Inclusive, temos um pacote no R chamado <a href="https://github.com/mnunes/modeloLEA/" target="_blank">modeloLEA</a>, escrito para agilizar e padronizar a formatação destes nossos relatórios.</p>

<p><img src="/images/IMG_2410_mini.jpg" alt="Apresentação do minicurso na 2nd Conference on Statistics and Data Science" /></p>

<p>O material do minicurso pode ser acessado em <a href="https://github.com/mnunes/2nd-csds" target="_blank">github.com/mnunes/2nd-csds</a>. Como sempre, o conteúdo disponibilizado é gratuito. Como amostra do trabalho, fiquem com o pdf que possui a <a href="https://github.com/mnunes/2nd-csds/blob/master/presentation/presentation.pdf" target="_blank">apresentação de slides</a> utilizada durante meu minicurso.</p>

<p>Se estiver interessado em uma versão deste minicurso para o seu evento, <a href="https://marcusnunes.me/contato/" target="_blank">entre em contato</a> para que possamos conversar sobre uma possível colaboração.</p>
]]></content>
		</item>
		
		<item>
			<title>Resultados da Competição de Ciência de Dados da UFRN 2019</title>
			<link>https://marcusnunes.me/posts/resultados-da-competicao-de-ciencia-de-dados-da-ufrn-2019/</link>
			<pubDate>Thu, 31 Oct 2019 19:03:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/resultados-da-competicao-de-ciencia-de-dados-da-ufrn-2019/</guid>
			<description>Conforme eu havia avisado anteriormente, o Departamento de Estatística da UFRN promoveu mais um vez a sua tradicional competição de Ciência de Dados entre os alunos da universidade.
Desta vez, a banca avaliadora não contava apenas com professores do Departamento de Estatística como na competição de 2018. No centro da foto abaixo, que contempla todos os competidores, é possível ver lado a lado Leonardo Bezerra, professor do IMD, Carla Vivacqua e eu, professores do Departamento de Estatística.</description>
			<content type="html"><![CDATA[

<p><a href="https://marcusnunes.me/posts/competicao-de-ciencia-de-dados-da-ufrn-2019/" target="_blank">Conforme eu havia avisado anteriormente</a>, o Departamento de Estatística da UFRN promoveu mais um vez a sua tradicional competição de Ciência de Dados entre os alunos da universidade.</p>

<p><img src="/images/ccd_2019.png" alt="Logo da Competição de Ciência de Dados da UFRN 2019" /></p>

<p>Desta vez, a banca avaliadora não contava apenas com professores do Departamento de Estatística como na <a href="https://marcusnunes.me/posts/como-foi-a-competicao-de-ciencia-de-dados/" target="_blank">competição de 2018</a>. No centro da foto abaixo, que contempla todos os competidores, é possível ver lado a lado Leonardo Bezerra, professor do IMD, Carla Vivacqua e eu, professores do Departamento de Estatística.</p>

<p><img src="/images/IMG_2195.jpg" alt="Competidores presentes na edição de 2019" /></p>

<p>Foram 21 competidores divididos em 7 equipes. O desafio era os dados coletados pelo INMET - Instituto Nacional de Meteorologia. Estes dados podem ser baixados a partir do endereço <a href="https://www.dropbox.com/s/7rriacb7c6vzf3m/ccd_2019.zip?dl=0" target="_blank">https://www.dropbox.com/s/7rriacb7c6vzf3m/ccd_2019.zip?dl=0</a> . O arquivo zipado tem 214MB. Eles foram obtidos com a ajuda de um pacote do R chamado inmetr - <a href="https://github.com/jdtatsch/inmetr" target="_blank">https://github.com/jdtatsch/inmetr</a> - , criado pelo Professor Jonatan Tatsch, da Universidade Federal de Santa Maria.</p>

<p>São dois arquivos dentro do zip. O arquivo <code>inmetr.csv</code> possui informações sobre as seguintes variáveis:</p>

<pre><code>variável                                descrição       unidade
    date                     data e hora da coleta             -
      id                   ID da estação de coleta             -
    prec                              precipitação            mm
    tair                         temperatura do ar graus Celsius
      tw                temperatura de bulbo úmido graus Celsius
    tmax                  temperatura máxima do ar graus Celsius
    tmin                  temperatura mínima do ar graus Celsius
   urmax                   umidade relativa máxima             %
    patm                       pressão atmosférica           hPa
    pnmm pressão atmosférica média ao nível do mar           hPa
      wd                          direção do vento         graus
   wsmax                          rajadas de vento           m/s
       n                              horas de sol             h
      cc                       cobertura de nuvens             -
    evap                                evaporação            mm
      ur                          umidade relativa             %
      ws                       velocidade do vento           m/s
</code></pre>

<p>O arquivo <code>bdmep_meta.csv</code> possui informações sobre as estações de coleta, relacionando-as com a variável id do arquivo <code>inmetr.csv</code>.</p>

<p>As equipes precisaram seguir algumas poucas regras gerais:</p>

<ul>
<li><p>O prazo limite para a entrega das análises era 23:59 de 27 de outubro de 2019.</p></li>

<li><p>As apresentações deveriam se limitar a 10 minutos e 3 slides</p></li>

<li><p>Qualquer análise era válida, desde visualizações dos dados até algum tipo de modelagem</p></li>
</ul>

<p>Após as apresentações, a banca decidiu que as 3 equipes melhores colocadas foram estas listadas abaixo, com as suas respectivas apresentações e relatórios linkados na sequência:</p>

<h2 id="3º-lugar-numberone">3º Lugar: numberOne</h2>

<p><img src="/images/IMG_2174.jpg" alt="Number One: Jordão de Lima Alves" /></p>

<p>Jordão de Lima Alves (Ciências Atuariais) criou a equipe de um homem só e faturou o terceiro lugar. Ele utilizou métodos de séries temporais para analisar alguns dados climatológicos da cidade de Apodi, no Rio Grande do Norte. Saiba mais detalhes sobre o trabalho dele lendo os <a href="/images/ciencia_de_dados_2019/numberOne_Apresentacao.pdf">slides</a> e o <a href="/images/ciencia_de_dados_2019/numberOne_Relatorio.pdf">relatório</a> entregues.</p>

<h2 id="2º-lugar-weeee">2º Lugar: weeee</h2>

<p><img src="/images/IMG_2178.jpg" alt="weeee: André Fellipe da Silva, Ianca Maria Leite da Costa, Vítor Saraiva Ramos, André Luis Andrade Machado e Mariana Costa" /></p>

<p>Os alunos André Fellipe da Silva (Graduação em Engenharia Elétrica), Ianca Maria Leite da Costa (Graduação em Engenharia Elétrica), Vítor Saraiva Ramos (Mestrado em Engenharia Elétrica e de Computação), André Luis Andrade Machado (Graduação em Engenharia Elétrica) e Mariana Costa (Graduação em Engenharia de Produção) se reuniram para analisar os dados meteorológicos disponíveis sobre 19/08/2019, o &ldquo;dia que virou noite&rdquo; devido à fumaça proveniente das queimadas na Amazônia. Baixe os <a href="/images/ciencia_de_dados_2019/weeee_Apresentacao.pdf">slides</a> e o <a href="/images/ciencia_de_dados_2019/weeee_Relatorio.pdf">relatório</a> para ver o que esta equipe produziu. Acesse a <a href="http://bit.ly/slides_wee" target="_blank">apresentação de slides na web</a> para ver uma animação que a equipe produziu para ilustrar os seus achados. As análises podem ser reproduzidas com o <a href="https://github.com/vitorsr/ccd" target="_blank">código em python</a> escrito pela equipe.</p>

<h2 id="1º-lugar-featuring-the-future">1º Lugar: Featuring the Future</h2>

<p><img src="/images/IMG_2185.jpg" alt="Number One: Daniel Marx Pinto Carvalho, Marcos Vinícius Gomes Jacinto, Gilvandro César de Medeiros e Marcus Vinicius Oliveira de Brito" /></p>

<p>Os grandes campeões do evento foram os alunos Daniel Marx Pinto Carvalho (Graduação em Tecnologia da Informação), Marcos Vinícius Gomes Jacinto (Programa de Pós-Graduação em Geodinâmica e Geofísica), Gilvandro César de Medeiros (Bacharelado em Ciências e Tecnologia) e Marcus Vinicius Oliveira de Brito (Graduação em Engenharia Elétrica). Como o conjunto de dados disponibilizado durante a competição possuía muitos dados faltantes, eles utilizaram <em>deep learning</em> para imputar as informações faltantes, além de analisar o potencial eólico das cidades brasileiras utilizando a distribuição Weibull. Seus achados estão disponíveis nos <a href="/images/ciencia_de_dados_2019/Featuring_the_Future_Slides.pdf">slides</a>, no <a href="/images/ciencia_de_dados_2019/Featuring_the_Future_Relatorio.pdf">relatório</a> e no <a href="https://github.com/gilvandrocesardemedeiros/CCD" target="_blank">código</a> fornecidos pela equipe.</p>
]]></content>
		</item>
		
		<item>
			<title>R ou Python? Qual a melhor ferramenta para trabalhar com Ciência de Dados?</title>
			<link>https://marcusnunes.me/posts/r-ou-python/</link>
			<pubDate>Wed, 09 Oct 2019 16:26:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/r-ou-python/</guid>
			<description>Já vou começar este texto opinativo com a resposta definitiva para a pergunta do título:
Qual é a melhor ferramenta para Análise de Dados? A melhor ferramenta para análise dados é a ferramenta que o usuário mais conhece. Seja Excel, R, python, Minitab, SAS, SPSS ou qualquer outra. O que importa é obter os resultados desejados de maneira rápida e confiável. Cada usuário vai ter necessidades diferentes e é muito provável que a melhor ferramenta para uma pessoa não sirva para outra.</description>
			<content type="html"><![CDATA[

<p>Já vou começar este texto opinativo com a resposta definitiva para a pergunta do título:</p>

<h1 id="qual-é-a-melhor-ferramenta-para-análise-de-dados">Qual é a melhor ferramenta para Análise de Dados?</h1>

<p>A melhor ferramenta para análise dados é a ferramenta que o usuário mais conhece. Seja Excel, <a href="https://marcusnunes.me/tags/r/" target="_blank">R</a>, <a href="https://marcusnunes.me/tags/python/" target="_blank">python</a>, Minitab, SAS, SPSS ou qualquer outra. O que importa é obter os resultados desejados de maneira rápida e confiável. Cada usuário vai ter necessidades diferentes e é muito provável que a melhor ferramenta para uma pessoa não sirva para outra.</p>

<p>Isto posto, afirmo que a minha linguagem preferida de programação para análise de dados é o <a href="https://marcusnunes.me/tags/r/" target="_blank">R</a>. Ela não é a linguagem mais popular do mundo, nem a mais rápida e nem a mais simples de aprender. Entretanto, é a que <strong>me</strong> serve melhor para aquilo que <strong>eu</strong> faço.</p>

<!--No restante do texto vou comparar [R](https://marcusnunes.me/tags/r/) e [python](https://marcusnunes.me/tags/python/) dentro das minhas limitações e dos meus conhecimentos e dizer porque prefiro uma em relação à outra.-->

<h1 id="por-que-usar-uma-linguagem-de-programação-para-analisar-dados">Por que usar uma linguagem de programação para analisar dados?</h1>

<p>O principal motivo é a documentação do processo de análise de dados. De maneira geral, ao utilizar uma ferramenta como Excel ou SPSS, o usuário não documenta aquilo que faz. Ele clica nos menus, obtém o seu resultado e termina o seu serviço. Não há nada de errado em fazer isso. O problema é que análises mais complexas acabam gerando mais passos intermediários entre a importação de dados e o resultado final da análise. A imagem abaixo, adaptada do livro <a href="https://r4ds.had.co.nz/" target="_blank">R for Data Science</a>, exemplifica bem como é o workflow geral de uma análise de dados do início ao fim:</p>

<p><img src="/images/workshop.png" alt="" /></p>

<p>Perceba que há muitos passos envolvidos. O processo completo, que começa pela importação dos dados, passa pela modelagem e finaliza na comunicação dos resultados, envolve muitos passos diferentes. Em especial, a parte destacada pelo retângulo azul, pode demorar muito. Encontrar o modelo ideal para os dados não é uma tarefa trivial. Assim, documentar estes passos é fundamental não apenas para que consigamos organizar nossas ideias, mas também para informar os outros membros da nossa equipe a respeito do trabalho que realizamos.</p>

<h1 id="por-que-usar-o-r-para-analisar-dados">Por que usar o R para analisar dados?</h1>

<p>A figura abaixo, obtida no <a href="https://julialang.org/benchmarks/" target="_blank">site da linguagem julia</a>, compara a velocidade de diversas linguagens de programação:</p>

<p><img src="/images/benchmarks.png" alt="" /></p>

<p>Note que <a href="https://marcusnunes.me/tags/r/" target="_blank">R</a> não é a mais rápida em nenhuma tarefa. Mesmo assim, prefiro utilizá-la porque escrevo código mais rápido nesta linguagem. O ganho de performance que eu teria rodando código em <a href="https://marcusnunes.me/tags/python/" target="_blank">python</a> seria perdido na hora de escrever os programas, pois sempre tenho que ficar checando manuais quando uso python. Ocorre o oposto quando uso R, pois sou fluente na linguagem e escrevo código para ela como escrevo meus textos em português ou em inglês.</p>

<p>O <a href="https://marcusnunes.me/tags/r/" target="_blank">R</a> apresenta algumas outras facilidades que eu já não consigo viver sem. Como preparo muito material didático, esta linguagem permite que eu mescle conteúdo teórico, trechos de códigos e outputs de programas de maneira muito prática. Sério, dá uma olhada neste material do <a href="https://htmlpreview.github.io/?https://github.com/mnunes/workshopR/blob/master/inst/doc/workshopR.html" target="_blank">Workshop de R Básico</a> que ministro e veja como a qualidade gráfica é impressionante. Faz quase 10 anos que uso R Sweave e seu sucessor RMarkdown com muito sucesso e não tenho interesse em aprender uma nova ferramenta se as que conheço atualmente já me satisfazem a contento.</p>

<p>Acabei utilizando esta característica do <a href="https://marcusnunes.me/tags/r/" target="_blank">R</a> para criar aplicações do RMarkdown em outras áreas. Por exemplo, os <a href="https://github.com/mnunes/modeloLEA/blob/master/documento_final.pdf" target="_blank">relatórios</a> dos alunos que participam do meu projeto de <a href="http://marcusnunes.me/consultoria/" target="_blank">consultoria estatística gratuita</a> são escritos usando RMarkdown, através de um <a href="https://github.com/mnunes/modeloLEA" target="_blank">pacote que eu mesmo criei</a>.</p>

<h1 id="conclusão">Conclusão</h1>

<p>Eu uso <a href="https://marcusnunes.me/tags/r/" target="_blank">R</a> porque ele facilita a minha vida. Programo na linguagem desde 2008 e, antes disso, utilizei S-Plus, sua versão proprietária. Por isso, o <a href="https://marcusnunes.me/tags/r/" target="_blank">R</a> é a minha opção preferida para analisar dados, preparar material didático e escrever relatórios e artigos científicos.</p>
]]></content>
		</item>
		
		<item>
			<title>Competição de Ciência de Dados da UFRN 2019</title>
			<link>https://marcusnunes.me/posts/competicao-de-ciencia-de-dados-da-ufrn-2019/</link>
			<pubDate>Thu, 03 Oct 2019 19:03:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/competicao-de-ciencia-de-dados-da-ufrn-2019/</guid>
			<description>Alguns professores do Departamento de Estatística da UFRN estão organizando mais uma competição de Ciência de Dados. Ela vai ocorrer entre os dias 23 e 30 de outubro de 2019 e está aberta para qualquer aluno matriculado regularmente em cursos de graduação ou pós-graduação da UFRN.
Esta competição faz parte das atividades da Semana da Estatística 2019, evento no qual muitas atividades estão programadas para toda a comunidade:
A competição consistirá em analisar um conjunto de dados fornecido pela organização da competição.</description>
			<content type="html"><![CDATA[

<p>Alguns professores do <a href="http://www.departamento.ufrn.br/estatistica" target="_blank">Departamento de Estatística da UFRN</a> estão organizando mais uma competição de Ciência de Dados. Ela vai ocorrer entre os dias 23 e 30 de outubro de 2019 e está aberta para qualquer aluno matriculado regularmente em cursos de graduação ou pós-graduação da UFRN.</p>

<p><img src="/images/ccd_2019.png" alt="Logo da Competição de Ciência de Dados da UFRN 2019" /></p>

<p>Esta competição faz parte das atividades da Semana da Estatística 2019, evento no qual muitas atividades estão programadas para toda a comunidade:</p>

<p><img src="/images/Banner_SE2019.jpg" alt="Banner da Semana da Estatística 2019" /></p>

<p>A competição consistirá em analisar um conjunto de dados fornecido pela organização da competição. Este conjunto de dados será mantido em sigilo até o início da competição, marcada para às 11:00 do dia 23 de outubro de 2019. A análise a ser realizada dependerá apenas da criatividade dos competidores. Será possível trabalhar com modelagem dos dados, ajuste de modelos de previsão ou visualização de informações.</p>

<p>Podem ser formadas equipes de até cinco participantes e todos os membros das equipes devem estar regularmente matriculados em algum curso de graduação ou pós-graduação da UFRN.</p>

<p>Corra que as inscrições vão apenas até o dia 20 de outubro, às 23:59! Além disso, as vagas são limitadas.</p>

<p><a href="https://docs.google.com/forms/d/1nvwvHN74yUMDe40vMEj0-ogfegKdikIzIoufo3DL8vE/viewform?edit_requested=true" target="_blank">Clique aqui para fazer a inscrição da sua equipe</a>.</p>

<p><a href="https://marcusnunes.me/posts/como-foi-a-competicao-de-ciencia-de-dados/" target="_blank">Clique aqui para saber foi a Competição de Ciência de Dados de 2018</a>.</p>

<hr />

<h1 id="regulamento">Regulamento</h1>

<p>Este é o regulamento da Competição de Ciência de Dados da UFRN, promovida pelo Departamento de Estatística desta universidade.</p>

<h2 id="introdução">Introdução</h2>

<p>Este regulamento tem como objetivo apresentar como será desenvolvida a Competição de Ciência de Dados 2019 promovida pelo Departamento de Estatística da UFRN.</p>

<h2 id="apresentação">Apresentação</h2>

<p>A Competição de Ciência de Dados 2019 consistirá em analisar um conjunto de dados fornecido pela organização da competição. Este conjunto de dados será mantido em sigilo até o início da competição, marcada para às 11:00 do dia 23 de outubro de 2019. Será a última atividade da Semana da Estatística UFRN 2019 antes do seu encerramento.</p>

<p>Os participantes da competição poderão submeter suas análises, reportadas em no máximo 4 slides (1 slide apenas com título e identificação + 3 slides com o trabalho realizado), até às 23:59 de 27 de outubro de 2019. As apresentações dos resultados destas análises serão públicas e ocorrerão a partir das 14:00 de 30 de outubro de 2019 no Anfiteatro A do CCET.</p>

<h2 id="regras-gerais">Regras Gerais</h2>

<ol>
<li>Este regulamento se refere à Competição de Ciência de Dados 2019 que está sendo promovida pelo Departamento de Estatística da UFRN.</li>
<li>Qualquer aluno matriculado regularmente em cursos de graduação ou pós-graduação da UFRN está apto a participar da competição.</li>
<li>Os competidores prepararão suas análises entre dias 23 e 27 de outubro de 2019, com a apresentação dos resultados marcada para o dia 30 de outubro de 2019, a partir das 14:00.</li>
<li>Os competidores deverão formar equipes de até 5 participantes.</li>
<li>Não é obrigatório que as equipes sejam formadas por alunos de apenas um curso de graduação ou pós-graduação.</li>
<li>Caso seja de interesse da equipe, é possível utilizar outros bancos de dados públicos como ferramentas de apoio à análise apresentada, desde que a fonte seja devidamente citada.</li>
<li>Os grupos deverão enviar para o email marcus@marcusnunes.me as suas apresentações de no máximo 4 slides (1 slide apenas com título e identificação + 3 slides com o trabalho realizado) até às 23:59 de 27 de outubro de 2019.</li>
<li>Além disso, um relatório curto, de no máximo uma página, também deve ser enviado para este email dentro deste prazo.</li>
<li>As apresentações e os relatórios de todas as equipes devem estar no formato pdf, nomeados da seguinte maneira: NomeEquipe_Apresentacao.pdf e NomeEquipe_Relatorio.pdf.</li>
</ol>

<h2 id="avaliação-dos-trabalhos">Avaliação dos Trabalhos</h2>

<ol>
<li>A partir das 14:00 do dia 30 de outubro, cada grupo terá até 10 minutos para realizar a apresentação dos seus resultados no Anfiteatro A do CCET.</li>
<li>As análises realizadas serão avaliadas por uma comissão de três professores do Departamento de Estatística da UFRN.</li>
<li>Nem todos os membros da equipe precisam falar durante a apresentação.</li>
<li>Nesta apresentação serão avaliados os resultados obtidos pelas equipes nos quesitos modelagem dos dados, visualização dos dados e comunicação dos resultados.</li>
</ol>

<h2 id="premiação">Premiação</h2>

<ol>
<li><p>Todos os grupos que enviarem os arquivos dentro do prazo estipulado e realizarem a apresentação oral a partir das 14:00 em 30 de outubro de 2019 receberão um certificado de participação no evento. Este certificado atesta que o aluno cumpriu 10 horas de Atividades Artístico-Científico-Culturais.</p></li>

<li><p>Os certificados irão conter informações sobre o nome da equipe, seus membros e o desempenho da equipe na competição.</p></li>

<li><p>Os membros das equipes melhores colocadas receberão medalhas.</p></li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>2º Workshop de R: Levando a Ciência de Dados para Todos</title>
			<link>https://marcusnunes.me/posts/workshop-de-r-na-ufrn/</link>
			<pubDate>Mon, 30 Sep 2019 11:07:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/workshop-de-r-na-ufrn/</guid>
			<description>Eu sou um fulbrighter. Como ex-aluno deste programa de intercâmbio, volta e meia sou convidado para participar de ventos promovidos pelo programa U.S.-Brazil Exchange Alumni (USBEA). O último destes eventos do qual participei rolou semana passada, em comemoração ao Dia Nacional do Voluntário no Brasil.
O projeto que desenvolvi se chamou 2º Workshop de R: Levando a Ciência de Dados para Todos e foi feito com apoio do Departamento de Estatística da UFRN, que cedeu a sala e os computadores com os quais o workshop pode ser desenvolvido.</description>
			<content type="html"><![CDATA[<p>Eu sou um <a href="https://fulbright.org.br/comissao/" target="_blank">fulbrighter</a>. Como ex-aluno deste programa de intercâmbio, volta e meia sou convidado para participar de ventos promovidos pelo programa U.S.-Brazil Exchange Alumni (USBEA). O último destes eventos do qual participei rolou semana passada, em comemoração ao Dia Nacional do Voluntário no Brasil.</p>

<p><img src="/images/usbea_month.png" alt="USBEA Month" /></p>

<p>O projeto que desenvolvi se chamou <strong>2º Workshop de R: Levando a Ciência de Dados para Todos</strong> e foi feito com apoio do <a href="http://www.departamento.ufrn.br/estatistica" target="_blank">Departamento de Estatística da UFRN</a>, que cedeu a sala e os computadores com os quais o workshop pode ser desenvolvido.</p>

<p><img src="/images/turma_do_workshop.jpg" alt="Turma do Workshop" /></p>

<p>Como pode ser visto na foto acima, o workshop trouxe muitas pessoas, todas de backgrounds diversos. Haviam desde alunos de graduação até doutorandos, todos interessados em conhecer um pouco mais sobre a linguagem de programação mais usada pelos estatísticos para analisarem seus dados.</p>

<p>Além disso, criei um pacote no R para facilitar a utilização do material didático do workshop. Seu nome é <code>workshopR</code> e ele pode ser baixado através <a href="https://github.com/mnunes/workshopR" target="_blank">deste link</a>. Um preview do material trabalhado durante o encontro está <a href="https://htmlpreview.github.io/?https://github.com/mnunes/workshopR/blob/master/inst/doc/workshopR.html" target="_blank">neste outro link aqui</a>.</p>
]]></content>
		</item>
		
		<item>
			<title>Consultoria Estatística na UFRN: Nosso Trabalho Sendo Divulgado no Oriente</title>
			<link>https://marcusnunes.me/posts/consultoria-estati%CC%81stica-na-ufrn-nosso-trabalho-sendo-divulgado-no-oriente/</link>
			<pubDate>Sat, 24 Aug 2019 14:45:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/consultoria-estati%CC%81stica-na-ufrn-nosso-trabalho-sendo-divulgado-no-oriente/</guid>
			<description>Um dos meus maiores interesses como professor do Departamento de Estatística da UFRN é formar bons prestadores de serviço de consultoria estatística. Acho fundamental que os bacharéis formados em nosso curso sejam capazes de entender as demandas de outras áreas, traduzi-las para o jargão estatístico e reportar os resultados obtidos numa linguagem fácil de compreender.
Por isso, junto com a Professora Carla Vivacqua, coordeno o Laboratório de Estatística Aplicada (LEA), órgão do Departamento de Estatística criado para prestar assessoria estatística gratuita para alunos, professores, pesquisadores e técnicos da universidade.</description>
			<content type="html"><![CDATA[

<p>Um dos meus maiores interesses como professor do Departamento de Estatística da UFRN é formar bons prestadores de serviço de consultoria estatística. Acho fundamental que os bacharéis formados em nosso curso sejam capazes de entender as demandas de outras áreas, traduzi-las para o jargão estatístico e reportar os resultados obtidos numa linguagem fácil de compreender.</p>

<p>Por isso, junto com a Professora Carla Vivacqua, coordeno o Laboratório de Estatística Aplicada (LEA), órgão do Departamento de Estatística criado para prestar assessoria estatística gratuita para alunos, professores, pesquisadores e técnicos da universidade. <a href="https://ufrn.br/imprensa/materias-especiais/3041/departamento-de-estatistica-oferece-servico-de-consultoria-gratuita-para-a-comunidade" target="_blank">O LEA já foi matéria de um número especial do boletim da universidade, em 11 de abril de 2017, no qual nossos serviços são descritos com detalhes</a>.</p>

<p>Pois eis que o LEA foi convidado, junto com outros 20 laboratórios ao redor do mundo, para participar de dois eventos em Kuala Lumpur, na Malásia. Estive lá entre 15 e 23 de Agosto, como representante do nosso laboratório, para participar destes eventos.</p>

<h1 id="2nd-lisa-2020-symposium">2nd LISA 2020 Symposium</h1>

<p>O primeiro evento que participei, chamado 2nd LISA 2020 Symposium, diz respeito a uma iniciativa mundial de laboratório de colaboração estatística. Esta iniciativa visa unir laboratórios de colaboração estatística em países em desenvolvimento. Seu nome é <a href="http://lisa2020.org" target="_blank">Laboratory for Interdisciplinary Statistical Analysis 2020</a> e foi criada pelo professor <a href="https://www.colorado.edu/amath/ervance" target="_blank">Eric Vance</a>, da University of Colorado Boulder, nos Estados Unidos. Até o momento, são mais de 20 países com laboratórios já funcionais ou em vias de serem implementados.</p>

<p><img src="/images/imagem01.png" alt="Laboratórios ao redor do mundo" /></p>

<p>Perceba como há vários laboratórios na África, mas quase nenhum na América Latina. Caso seja do teu interesse ou caso tu conheça alguém interessado em criar um laboratório de colaboração estatística no Brasil, Argentina, Uruguai ou outro país do nosso continente, <a href="https://marcusnunes.me/contato/" target="_blank">entre em contato comigo</a> para conversarmos a respeito de como implementar algo assim na tua universidade.</p>

<p>O professor Vance organizou este simpósio em Kuala Lumpur envolvendo coordenadores de laboratórios com missões semelhantes ao que temos na UFRN. Os países que enviaram representantes para participarem do simpósio, além dos Estados Unidos como organizadores, foram</p>

<ul>
<li>África do Sul</li>
<li>Brasil</li>
<li>Etiópia</li>
<li>Gana</li>
<li>Índia</li>
<li>Nepal</li>
<li>Nigéria</li>
<li>Paquistão</li>
<li>Tanzânia</li>
<li>Zimbábue</li>
</ul>

<p><img src="/images/foto02.jpg" alt="Representantes de laboratórios ao redor do mundo" /></p>

<p>Foi uma experiência enriquecedora, na qual pude comparar minhas experiências com as deles. Assim, pudemos todos perceber como existem dificuldades semelhantes em fazer estatística ao redor do mundo, principalmente nos países em desenvolvimento. Uma queixa muito comum entre todos os participantes foi a falta de verba, seguida por falta de apoio da universidade e pelo desinteresse dos colegas de departamento.</p>

<p>Além das experiências trocadas com os outros participantes, que contribuíram com relatos a respeito de ensino de estatística e análise de dados, tive a oportunidade de participar de quatro workshops:</p>

<ul>
<li>Collaboration Skills</li>
<li>Creating and Administering a Stat Lab</li>
<li>Transforming Evidence to Action</li>
<li>Grant Writing</li>
</ul>

<p>Particularmente, creio que o workshop de Grant Writing vai ser o mais útil de todos, dados os cortes de verbas que temos enfrentado nos últimos anos.</p>

<h1 id="62nd-isi-world-statistics-congress">62nd ISI World Statistics Congress</h1>

<p>O segundo evento do qual participei foi o 62nd World Statistics Congress. Neste evento apresentei o trabalho &ldquo;Effects of Participation in a Statistical Laboratory on Statistics Students&rdquo;. Este trabalho serviu para apresentar o LEA para o mundo, mostrando como é o nosso fluxo de trabalho no Brasil e como lidamos com as dificuldades de encontramos por aqui.</p>

<p><img src="/images/foto03.jpg" alt="Cosplay de palestrante 01" /></p>

<p><img src="/images/foto03a.jpg" alt="Cosplay de palestrante 02" /></p>

<p>A repercussão da minha apresentação foi muito boa, com uma discussão envolvendo a plateia ao final da minha apresentação. Foram quase 10 minutos de perguntas e respostas a respeito da iniciativa que mantemos no Brasil. Além disso, fui procurado por professores de outros países interessados em implementar um laboratório como o LEA em suas universidades. Para quem se interessou pelo assunto, <a href="/images/Marcus_Nunes_62nd_ISI_WSC.pdf">este é o pdf com os slides que apresentei no evento</a>.</p>

<p>Por fim, também fui o moderador da sessão &ldquo;How to Scale Up Statistical Analysis Capacity to Achieve the Sustainable Development Goals&rdquo;. Foi uma sessão extremamente produtiva, na qual os palestrantes mostraram como eles são capazes de aumentar a contribuição dos laboratórios de colaboração estatística em seus países de origem e como é possível, mesmo com poucos recursos financeiros, realizar projetos de grande impacto social.</p>

<p><img src="/images/foto04.jpg" alt="Mediador" /></p>

<p>Minha participação neste evento se concretizou devido a um prêmio que ganhei da United States Agency for International Development (USAID), que cobriu meus gastos com translado, hospedagem e alimentação, além dos custos com a inscrição no congresso.</p>

<p><a href="https://www.instagram.com/grandeabobora/" target="_blank">Aproveita e me segue no instagram para ver umas fotos que bati na Malásia e estou publicando de forma homeopática</a>.</p>
]]></content>
		</item>
		
		<item>
			<title>Análise de Sentimentos com o R: Bojack Horseman vs Brooklyn Nine-Nine</title>
			<link>https://marcusnunes.me/posts/analise-de-sentimentos-com-r-bojack-horseman-vs-brooklyn-99/</link>
			<pubDate>Sun, 28 Jul 2019 08:20:00 -0300</pubDate>
			
			<guid>https://marcusnunes.me/posts/analise-de-sentimentos-com-r-bojack-horseman-vs-brooklyn-99/</guid>
			<description>Introdução Analisar sentimentos em texto é uma das coisas que sempre desejei aprender a fazer. Ao descobrir o post Bojack Horseman and Tidy Data Principles (Part 1) senti que era o momento de dar o pontapé inicial no assunto. Mas em vez de simplesmente reaplicar aquilo que o meu texto inspirador fez, decidi ir além, comparando duas séries de TV que gosto bastante.
Para tal, escolhi Bojack Horseman e Brooklyn Nine-Nine para a empreitada.</description>
			<content type="html"><![CDATA[


<div id="introdução" class="section level1">
<h1>Introdução</h1>
<p>Analisar sentimentos em texto é uma das coisas que sempre desejei aprender a fazer. Ao descobrir o post <a href="https://pacha.hk/blog/2019/07/16/bojack-horseman-and-tidy-data-principles-part-1/">Bojack Horseman and Tidy Data Principles (Part 1)</a> senti que era o momento de dar o pontapé inicial no assunto. Mas em vez de simplesmente reaplicar aquilo que o meu texto inspirador fez, decidi ir além, comparando duas séries de TV que gosto bastante.</p>
<p>Para tal, escolhi <a href="https://pt.wikipedia.org/wiki/BoJack_Horseman">Bojack Horseman</a> e <a href="https://pt.wikipedia.org/wiki/Brooklyn_Nine-Nine">Brooklyn Nine-Nine</a> para a empreitada. Optei pelas duas por uma série de motivos. O principal deles, como dito anteriormente, é o fato de eu gostar de ambas. Além disso, as duas séries são consideradas <em>sitcoms</em>, o que as coloca no mesmo gênero televisivo. Não obstante, são séries contemporâneas: Bojack Horseman estreou em 2014, enquanto Brooklyn Nine-Nine é apenas um ano mais velha. Assm, decidi me concentrar nas cinco primeiras temporadas de cada seriado.</p>
<p>O que as difere são os temas abordados. Enquanto Bojack Horseman é uma série brutalmente triste, que explora a relação do protagonista com a sua depressão, Brooklyn Nine-Nine aposta em piadas leves e temas como inclusão para contar a sua história.</p>
<p>Assim, a minha hipótese é que Bojack Horseman use sentimentos mais negativos em seus diálogos, enquanto Brooklyn Nine-Nine seja uma série mais positiva.</p>
</div>
<div id="obtenção-dos-dados" class="section level1">
<h1>Obtenção dos Dados</h1>
<p>O ideal seria utilizar os roteiros dos seriados como base para a minha análise. Mas isto so mostrou impossível, pois desejo encontrar resultados em português. Portanto, decidi utilizar as legendas traduzidas para fazer a minha análise. Por sorte, o site <a href="http://legendas.tv">Legendas TV</a> possui todas as legendas das cinco primeiras temporadas destes seriados. Como estas legendas estão organizadas em um arquivo único por temporada, o trabalho de baixá-las tornou-se bem menor.</p>
</div>
<div id="tratamento-e-análise-dos-dados" class="section level1">
<h1>Tratamento e Análise dos Dados</h1>
<div id="palavras-mais-frequentes" class="section level2">
<h2>Palavras Mais Frequentes</h2>
<p>A primeira parte da análise é carregar os pacotes necessários para realizá-la. Note que o pacote <code>subtools</code> está hospedado no GitHub, o que implica que não basta rodar <code>install.packages(subtools)</code> para que ele seja instalado.</p>
<pre class="r"><code># pacotes necessarios

library(subtools) # devtools::install_github(&quot;fkeck/subtools&quot;)
library(tm)
library(tidyverse)
theme_set(theme_bw())
library(gridExtra)
library(reshape2)</code></pre>
<p>Como cada episódio dos seriados está armazenado em um arquivo .srt diferente, é necessário ter uma forma prática de ler todos estes arquivos de uma vez. A função <code>subtools::read.subtitles.serie</code> é perfeita para isso, pois além de ler todos os arquivos de uma vez só, ela também os organiza por episódio e temporada.</p>
<pre class="r"><code>#######################
### bojack horseman ###
#######################

# leitura das legendas dos episodios

bojack &lt;- read.subtitles.serie(dir = &quot;subtitles/bojack_horseman/&quot;)</code></pre>
<p>Após a leitura das legendas, precisamos transformá-las em um <em><a href="https://pt.wikipedia.org/wiki/Corpus_lingu%C3%ADstico">corpus</a></em>. Isto é fundamental para que possamos proceder com a limpeza do texto, aplicando nele as seguintes transformações:</p>
<ul>
<li>converter todas as letras para sua versão minúscula</li>
<li>remover sinais de pontuação</li>
<li>remover números</li>
<li>remover <em><a href="https://pt.wikipedia.org/wiki/Palavra_vazia">stopwords</a></em> (palavras vazias de sentido, como: e, para, de e similares)</li>
<li>remover espaços em branco</li>
</ul>
<pre class="r"><code># limpeza do texto

bojack_corpus &lt;- tmCorpus(bojack)

bojack_corpus &lt;- tm_map(bojack_corpus, content_transformer(tolower))
bojack_corpus &lt;- tm_map(bojack_corpus, removePunctuation)
bojack_corpus &lt;- tm_map(bojack_corpus, removeNumbers)
bojack_corpus &lt;- tm_map(bojack_corpus, removeWords, stopwords(&quot;portuguese&quot;))
bojack_corpus &lt;- tm_map(bojack_corpus, stripWhitespace)
bojack_corpus &lt;- TermDocumentMatrix(bojack_corpus)

bojack_corpus_matrix &lt;- as.matrix(bojack_corpus)</code></pre>
<p>Em seguida, é preciso proceder com a lematização do texto. É necessário identificar e converter formas flexionadas das palavras para as suas versões dicionarizadas. Por exemplo, é preciso tomar as palavras <em>comi</em>, <em>comemos</em>. <em>comeríamos</em>, <em>comia</em> e transformá-las todas em <em>comer</em>.</p>
<p>Não encontrei nenhum pacote que fizesse uma lematização aceitável em português. Assim, tive que implementar a minha própria, baseado no <a href="https://github.com/michmech/lemmatization-lists">dicionário de lematização encontrado neste link</a>. Ela ficou um pouco lenta de ser aplicada, mas foi a melhor solução que encontrei na minha pesquisa.</p>
<pre class="r"><code># lemmatizacao

lemma_dic &lt;- read.delim(file = &quot;lemmatization/lemmatization-pt.txt&quot;, header = FALSE, stringsAsFactors = FALSE)
names(lemma_dic) &lt;- c(&quot;stem&quot;, &quot;term&quot;)

# palavras do bojack que estao no dicionario

palavras &lt;- row.names(bojack_corpus_matrix)

for (j in 1:length(palavras)){
  comparacao &lt;- palavras[j] == lemma_dic$term
  if (sum(comparacao) == 1){
    palavras[j] &lt;- as.character(lemma_dic$stem[comparacao])
  } else {
    palavras[j] &lt;- palavras[j]
  }
}

palavras_bojack &lt;- palavras

bojack_corpus_df &lt;- as.data.frame(bojack_corpus_matrix)
row.names(bojack_corpus_df) &lt;- NULL
bojack_corpus_df$palavras &lt;- palavras_bojack</code></pre>
<p>Após a lematização, é preciso contar as ocorrências de cada palavra e preparar os conjuntos de dados para que sejam plotados:</p>
<pre class="r"><code># agrupar os resultados 

bojack_corpus_df &lt;- bojack_corpus_df %&gt;%
  group_by(palavras) %&gt;%
  summarise_all(sum)

temporadas &lt;- rep(1:5, each = 12)
bojack_corpus_df_col &lt;- t(apply(bojack_corpus_df[, 2:61], 1, function(x) tapply(x, temporadas, sum)))
colnames(bojack_corpus_df_col) &lt;- paste(&quot;S0&quot;, 1:5, sep = &quot;&quot;)
bojack_corpus_df_col &lt;- data.frame(palavra = bojack_corpus_df$palavras,
                                   bojack_corpus_df_col)

bojack_corpus_melt &lt;- melt(bojack_corpus_df_col)
names(bojack_corpus_melt) &lt;- c(&quot;palavra&quot;, &quot;temporada&quot;, &quot;ocorrencias&quot;)


# funcao para plotar os graficos de barra

plot.seriado &lt;- function(dados, season, cor = 0){
  
  grafico &lt;- dados %&gt;%
    filter(temporada == season) %&gt;%
    top_n(n = 10, wt = ocorrencias) %&gt;%
    arrange(desc(ocorrencias)) %&gt;%
    ggplot(., aes(x = reorder(palavra, ocorrencias), y = ocorrencias, fill = temporada)) +
    geom_col(show.legend = FALSE) +
    labs(x = &quot;&quot;, y = &quot;&quot;, title = season) +
    coord_flip() +
    scale_fill_viridis_d(begin = cor)
  
  return(grafico)  
  
}</code></pre>
<p>No fim, o que obtemos é o seguinte gráfico:</p>
<pre class="r"><code>s01 &lt;- plot.seriado(bojack_corpus_melt, &quot;S01&quot;, 0.00)
s02 &lt;- plot.seriado(bojack_corpus_melt, &quot;S02&quot;, 0.25)
s03 &lt;- plot.seriado(bojack_corpus_melt, &quot;S03&quot;, 0.50)
s04 &lt;- plot.seriado(bojack_corpus_melt, &quot;S04&quot;, 0.75)
s05 &lt;- plot.seriado(bojack_corpus_melt, &quot;S05&quot;, 1.00)

grid.arrange(s01, s02, s03, s04, s05, left = &quot;Palavras&quot;, bottom = &quot;Número de Ocorrências&quot;)</code></pre>
<p><img src="/posts/analise-de-sentimentos-com-R-bojack-horseman-vs-brooklyn-99_files/figure-html/bojack_plots-1.png" width="672" /></p>
<p>Note que o verbo <strong>ir</strong> é o que mais aparece em todas as temporadas de Bojack Horseman, com <strong>querer</strong> e <strong>fazer</strong> alternando a segunda posição.</p>
<p>A preparação dos dados para a análise dos diálogos de Brooklyn Nine-Nine é análoga à realizada para Bojack Horseman.</p>
<pre class="r"><code>###################
### brooklyn 99 ###
###################

# leitura das legendas dos episodios

brooklyn99 &lt;- read.subtitles.serie(dir = &quot;subtitles/brooklyn99/&quot;)

# limpeza do texto

brooklyn99_corpus &lt;- tmCorpus(brooklyn99)

brooklyn99_corpus &lt;- tm_map(brooklyn99_corpus, content_transformer(tolower))
brooklyn99_corpus &lt;- tm_map(brooklyn99_corpus, removePunctuation)
brooklyn99_corpus &lt;- tm_map(brooklyn99_corpus, removeNumbers)
brooklyn99_corpus &lt;- tm_map(brooklyn99_corpus, removeWords, stopwords(&quot;portuguese&quot;))
brooklyn99_corpus &lt;- tm_map(brooklyn99_corpus, stripWhitespace)
brooklyn99_corpus &lt;- TermDocumentMatrix(brooklyn99_corpus)

brooklyn99_corpus_matrix &lt;- as.matrix(brooklyn99_corpus)

# lemmatizacao

lemma_dic &lt;- read.delim(file = &quot;lemmatization/lemmatization-pt.txt&quot;, header = FALSE, stringsAsFactors = FALSE)
names(lemma_dic) &lt;- c(&quot;stem&quot;, &quot;term&quot;)

# palavras do brooklyn99 que estao no dicionario

palavras &lt;- row.names(brooklyn99_corpus_matrix)

for (j in 1:length(palavras)){
  comparacao &lt;- palavras[j] == lemma_dic$term
  if (sum(comparacao) == 1){
    palavras[j] &lt;- as.character(lemma_dic$stem[comparacao])
  } else {
    palavras[j] &lt;- palavras[j]
  }
}

palavras_brooklyn99 &lt;- palavras

brooklyn99_corpus_df &lt;- as.data.frame(brooklyn99_corpus_matrix)
row.names(brooklyn99_corpus_df) &lt;- NULL
brooklyn99_corpus_df$palavras &lt;- palavras_brooklyn99

# agrupar os resultados 

brooklyn99_corpus_df &lt;- brooklyn99_corpus_df %&gt;%
  group_by(palavras) %&gt;%
  summarise_all(sum)

temporadas &lt;- c(rep(1, 22), 
                rep(2, 23), 
                rep(3, 23), 
                rep(4, 22), 
                rep(5, 22))

brooklyn99_corpus_df_col &lt;- t(apply(brooklyn99_corpus_df[, 2:113], 1, function(x) tapply(x, temporadas, sum)))
colnames(brooklyn99_corpus_df_col) &lt;- paste(&quot;S0&quot;, 1:5, sep = &quot;&quot;)
brooklyn99_corpus_df_col &lt;- data.frame(palavra = brooklyn99_corpus_df$palavras,
                                       brooklyn99_corpus_df_col)

brooklyn99_corpus_melt &lt;- melt(brooklyn99_corpus_df_col)
names(brooklyn99_corpus_melt) &lt;- c(&quot;palavra&quot;, &quot;temporada&quot;, &quot;ocorrencias&quot;)

# funcao para plotar os graficos de barra

plot.seriado &lt;- function(dados, season, cor = 0){
  
  grafico &lt;- dados %&gt;%
    filter(temporada == season) %&gt;%
    top_n(n = 10, wt = ocorrencias) %&gt;%
    arrange(desc(ocorrencias)) %&gt;%
    ggplot(., aes(x = reorder(palavra, ocorrencias), y = ocorrencias, fill = temporada)) +
    geom_col(show.legend = FALSE) +
    labs(x = &quot;&quot;, y = &quot;&quot;, title = season) +
    coord_flip() +
    scale_fill_viridis_d(begin = cor)
  
  return(grafico)  
  
}</code></pre>
<p>E ao fazer a contagem das palavras que mais aparecem e colocá-las em um gráfico, eis que o resultado é praticamente idêntico ao de Bojack Horseman:</p>
<pre class="r"><code>s01 &lt;- plot.seriado(brooklyn99_corpus_melt, &quot;S01&quot;, 0.00)
s02 &lt;- plot.seriado(brooklyn99_corpus_melt, &quot;S02&quot;, 0.25)
s03 &lt;- plot.seriado(brooklyn99_corpus_melt, &quot;S03&quot;, 0.50)
s04 &lt;- plot.seriado(brooklyn99_corpus_melt, &quot;S04&quot;, 0.75)
s05 &lt;- plot.seriado(brooklyn99_corpus_melt, &quot;S05&quot;, 1.00)

grid.arrange(s01, s02, s03, s04, s05, left = &quot;Palavras&quot;, bottom = &quot;Número de Ocorrências&quot;)</code></pre>
<p><img src="/posts/analise-de-sentimentos-com-R-bojack-horseman-vs-brooklyn-99_files/figure-html/b99_plot-1.png" width="672" /></p>
<pre class="r"><code>sentimentos &lt;- read.table(file = &quot;sentiment/sentiword.txt&quot;, sep = &quot;\t&quot;, header = TRUE)

sentimentos &lt;- sentimentos %&gt;%
  group_by(Termo) %&gt;%
  summarise(positivo = max(PosScore), negativo = max(NegScore)) %&gt;%
  mutate(Termo = trimws(Termo, which = &quot;left&quot;))

pos &lt;- sentimentos[, c(1, 2)]
neg &lt;- sentimentos[, c(1, 3)]

# sentimento para cada episodio

bojack_sentimento_positivo &lt;- 0
bojack_sentimento_negativo &lt;- 0

for (j in 1:(dim(bojack_corpus_df)[2]-1)){
  
  # palavras do j-esimo episodio
  
  a &lt;- bojack_corpus_matrix[, j]
  a &lt;- data.frame(Termo = names(a),
                  Ocorrencias = a)

  row.names(a) &lt;- NULL
  
  # juntando sentimentos com as palavras do episodio - caso positivo
  
  x &lt;- left_join(a, pos, by = &quot;Termo&quot;) %&gt;%
    na.omit()

  sentimento_positivo &lt;- sum(x$Ocorrencias*x$positivo)/sum(a$Ocorrencias)
  
  # juntando sentimentos com as palavras do episodio - caso negativo

  x &lt;- left_join(a, neg, by = &quot;Termo&quot;) %&gt;%
    na.omit()

  sentimento_negativo &lt;- sum(x$Ocorrencias*x$negativo)/sum(a$Ocorrencias)
  
  bojack_sentimento_positivo[j] &lt;- sentimento_positivo
  bojack_sentimento_negativo[j] &lt;- sentimento_negativo
}

bojack_plot &lt;- data.frame(episodio = 1:length(bojack_sentimento_positivo),
                          temporada = factor(temporadas),
                          positivo = bojack_sentimento_positivo,
                          negativo = bojack_sentimento_negativo)

# sentimento para cada episodio

brooklyn99_sentimento_positivo &lt;- 0
brooklyn99_sentimento_negativo &lt;- 0

for (j in 1:(dim(brooklyn99_corpus_df)[2]-1)){
  
  # palavras do j-esimo episodio
  
  a &lt;- brooklyn99_corpus_matrix[, j]
  a &lt;- data.frame(Termo = names(a),
                  Ocorrencias = a)
  
  row.names(a) &lt;- NULL
  
  # juntando sentimentos com as palavras do episodio - caso positivo
  
  x &lt;- left_join(a, pos, by = &quot;Termo&quot;) %&gt;%
    na.omit()
  
  sentimento_positivo &lt;- sum(x$Ocorrencias*x$positivo)/sum(a$Ocorrencias)
  
  # juntando sentimentos com as palavras do episodio - caso negativo
  
  x &lt;- left_join(a, neg, by = &quot;Termo&quot;) %&gt;%
    na.omit()
  
  sentimento_negativo &lt;- sum(x$Ocorrencias*x$negativo)/sum(a$Ocorrencias)
  
  brooklyn99_sentimento_positivo[j] &lt;- sentimento_positivo
  brooklyn99_sentimento_negativo[j] &lt;- sentimento_negativo
}

brooklyn99_plot &lt;- data.frame(episodio = 1:length(brooklyn99_sentimento_positivo),
                              temporada = factor(temporadas),
                              positivo = brooklyn99_sentimento_positivo,
                              negativo = brooklyn99_sentimento_negativo)</code></pre>
</div>
<div id="análise-de-sentimentos" class="section level2">
<h2>Análise de Sentimentos</h2>
<p>É possível atribuir pesos positivos e negativos a palavras, em uma escala de 0 a 1. Por exemplo, a palavra incapaz pode ter valor 0.75 positivo, enquanto a palavra hiperventilar tem peso negativo de 0.5. Ao atribuir estes pesos para as palavras ditas no seriado, é possível verificar como, em uma escala de 0 a 1 para valores positivos e de -1 a 0 para valores negativos, como estão os diálogos das séries. O dicionário <a href="https://github.com/Pedro-Thales/SentiWordNet-PT-BR">SentiWordNet-PT-BR</a>, criado pelo Pedro Thales, me ajudou muito nesta tarefa. Os resultados obtidos estão nas figuras abaixo.</p>
<pre class="r"><code>ggplot(bojack_plot, aes(x = episodio, colour = temporada)) +
  geom_line(aes(y = positivo)) +
  geom_line(aes(y = -negativo)) +
  scale_x_continuous(breaks = seq(12, 60, 12)) +
  labs(x = &quot;Episódio&quot;, y = &quot;Sentimento&quot;, colour = &quot;Temporada&quot;, title = &quot;Bojack Horseman&quot;) +
  scale_colour_viridis_d()</code></pre>
<p><img src="/posts/analise-de-sentimentos-com-R-bojack-horseman-vs-brooklyn-99_files/figure-html/plotSentimento-1.png" width="672" /></p>
<pre class="r"><code>ggplot(brooklyn99_plot, aes(x = episodio, colour = temporada)) +
  geom_line(aes(y = positivo)) +
  geom_line(aes(y = -negativo)) +
  scale_x_continuous(breaks = c(22, 45, 68, 90, 112)) +
  labs(x = &quot;Episódio&quot;, y = &quot;Sentimento&quot;, colour = &quot;Temporada&quot;, title = &quot;Brooklyn 99&quot;) +
  scale_colour_viridis_d()</code></pre>
<p><img src="/posts/analise-de-sentimentos-com-R-bojack-horseman-vs-brooklyn-99_files/figure-html/plotSentimento-2.png" width="672" /></p>
<p>Novamente, parece não haver muita diferença de uma série para outra.</p>
</div>
</div>
<div id="conclusão" class="section level1">
<h1>Conclusão</h1>
<p>Reconheço que este não é o resultado que eu esperava. Eu imaginava que as palavras com maior frequência para Bojack Horseman teriam conotação negativa, enquanto em Brooklyn Nine-Nine elas teriam mais conotação positiva. Pelo visto, me enganei.</p>
<p>Caberia fazer uma segunda análise nestes dados, talvez com os diálogos originais. Afinal, como as traduções que usei não são, pode ser que elas estejam influenciando no resultado final da análise. Além disso, é possível que meus dicionários de lematização e sentimentos possuam problemas, fazendo com que os resultados não sejam exatamente aqueles que ocorrem na língua original dos seriados.</p>
<p>De toda forma, foi uma análise divertida de fazer. Tentarei repeti-la co fututo, mas aí com <em>corpus</em> originais do português.</p>
<p>Os arquivos utilizados nesta análise estão <a href="https://github.com/mnunes/tv_series">neste repositório do GitHub</a>.</p>
</div>
]]></content>
		</item>
		
	</channel>
</rss>
